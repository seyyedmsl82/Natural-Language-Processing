{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *مجموعه داده*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### الف"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qrels Definitions:\n",
      "0: Not Relevant\n",
      "1: Marginally Relevant\n",
      "2: Relevant\n",
      "3: Highly Relevant\n",
      "Dataset Metadata:\n",
      "Total number of documents: 1400\n",
      "Total number of queries: 225\n",
      "Total number of relevance judgments: 1484\n",
      "Average judgments per query: 6.60\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "import re\n",
    "\n",
    "folder_path = './'\n",
    "# Step 1: Extract the .tar.gz file\n",
    "with tarfile.open(folder_path+\"cran.tar.gz\", \"r:\") as tar:\n",
    "    tar.extractall(folder_path+\"cranfield_dataset\")\n",
    "\n",
    "# Paths to the extracted files\n",
    "docs_path = folder_path+\"cranfield_dataset/cran.all.1400\"\n",
    "queries_path = folder_path+\"cranfield_dataset/cran.qry\"\n",
    "qrels_path = folder_path+\"cranfield_dataset/cranqrel\"\n",
    "\n",
    "# Step 1: Load documents from 'cran.all.1400'\n",
    "documents = {}\n",
    "with open(docs_path, 'r') as file:\n",
    "    content = file.read()\n",
    "    docs = re.split(r\"\\.I \", content)[1:]  # Split by document identifier prefix\n",
    "    for doc in docs:\n",
    "        lines = doc.splitlines()\n",
    "        doc_id = lines[0].strip()\n",
    "        doc_text = \"\\n\".join(lines[2:])  # Skip .T and first line for title/author, rest is content\n",
    "        documents[doc_id] = doc_text\n",
    "\n",
    "# Step 2: Load queries from 'cran.qry'\n",
    "queries = {}\n",
    "with open(queries_path, 'r') as file:\n",
    "    content = file.read()\n",
    "    qry_sections = re.split(r\"\\.I \", content)[1:]  # Split by query identifier prefix\n",
    "    for idx, qry in enumerate(qry_sections):\n",
    "        lines = qry.splitlines()\n",
    "        query_text = \"\\n\".join(lines[2:])  # Skip the first 2 lines to get query text\n",
    "        queries[idx + 1] = query_text  # Use a continuous index from 1 to total count\n",
    "\n",
    "# Step 3: Load and remap relevance judgments from 'cranqrel'\n",
    "relevance_judgments = {i + 1: set() for i in range(len(queries))}\n",
    "# query_id_map = {old_id: new_id for new_id, old_id in enumerate(sorted(queries.keys()), start=1)}\n",
    "\n",
    "with open(qrels_path, 'r') as file:\n",
    "    for line in file:\n",
    "        query_id, doc_id, relevance = map(int, line.split())\n",
    "        # new_query_id = query_id_map.get(query_id)\n",
    "        if query_id and relevance >= 2:  # Only consider relevance >= 2\n",
    "            relevance_judgments[query_id].add(str(doc_id))\n",
    "\n",
    "# Step 4: Define qrels_defs() and metadata() equivalents\n",
    "def qrels_defs():\n",
    "    print(\"Qrels Definitions:\")\n",
    "    print(\"0: Not Relevant\")\n",
    "    print(\"1: Marginally Relevant\")\n",
    "    print(\"2: Relevant\")\n",
    "    print(\"3: Highly Relevant\")\n",
    "\n",
    "def metadata(documents, queries, relevance_judgments):\n",
    "    print(\"Dataset Metadata:\")\n",
    "    print(f\"Total number of documents: {len(documents)}\")\n",
    "    print(f\"Total number of queries: {len(queries)}\")\n",
    "    total_rels = sum(len(docs) for docs in relevance_judgments.values())\n",
    "    print(f\"Total number of relevance judgments: {total_rels}\")\n",
    "    print(f\"Average judgments per query: {total_rels / len(queries):.2f}\")\n",
    "\n",
    "# Call the functions to print qrels definitions and metadata\n",
    "qrels_defs()\n",
    "metadata(documents, queries, relevance_judgments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *بخش اول*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### الف"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we train a WordPeice tokenizer on the dcuments and create vocabulary using the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./tokenizer\\\\vocab.txt']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tokenizers import BertWordPieceTokenizer\n",
    "import os\n",
    "\n",
    "tokenizer = BertWordPieceTokenizer(\n",
    "    clean_text = True,\n",
    "    strip_accents = False\n",
    ")\n",
    "\n",
    "document_values = documents.values()\n",
    "\n",
    "vocab_size = 20000\n",
    "tokenizer.train_from_iterator(document_values, vocab_size=vocab_size)\n",
    "\n",
    "os.mkdir('./tokenizer')\n",
    "tokenizer.save_model('./tokenizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import math\n",
    "from collections import Counter, defaultdict\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('./tokenizer')\n",
    "\n",
    "# Tokenize and count terms in each document\n",
    "all_tokens = {}\n",
    "doc_lengths = {}\n",
    "\n",
    "for doc_id, text in documents.items():\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    all_tokens[doc_id] = tokens\n",
    "    doc_lengths[doc_id] = len(tokens)\n",
    "\n",
    "vocab = tokenizer.get_vocab()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ب"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the created vocabulary, we build Term Frequency Embedding vectors for tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "token_to_index = {token: idx for idx, token in enumerate(vocab)}  # Map tokens to indices\n",
    "\n",
    "tf_matrix = defaultdict()\n",
    "\n",
    "for doc_id, text in documents.items():\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    \n",
    "    # Initialize (length=vocab size)\n",
    "    tf_vector = [0] * len(vocab)\n",
    "    \n",
    "    token_counts = defaultdict(int)\n",
    "    for token_id in token_ids:\n",
    "        token_counts[token_id] += 1\n",
    "    \n",
    "    # Fill the vector with term frequencies\n",
    "    for token_id, count in token_counts.items():\n",
    "        token = tokenizer.convert_ids_to_tokens([token_id])[0]\n",
    "        if token in token_to_index:\n",
    "            idx = token_to_index[token]\n",
    "            tf_vector[idx] = count\n",
    "    \n",
    "    tf_matrix[doc_id] = tf_vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-4-a:\n",
    "After TF vectors creation, we evaluate its functionality using the provided Relevance Judgments. For this sake we:\n",
    "\n",
    "        1: Create Term Frequency vectors for queries\n",
    "\n",
    "        2: Calculate the similarity between each query and document\n",
    "\n",
    "        3: We search for the most 5 similar documents\n",
    "        \n",
    "        4: Using the relevace judgments and most 5 similar documents, we calculate MP@5 evaluation criteria\n",
    "\n",
    "This method has the least accuracy comapres the other two, with hte MP@5 criteria of 12%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for the queries\n",
    "query_embeddings = defaultdict()\n",
    "\n",
    "for quer_id, text in queries.items():\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    tf_vector = [0] * len(vocab)\n",
    "\n",
    "    token_counts = defaultdict(int)\n",
    "    for token_id in token_ids:\n",
    "        token_counts[token_id] += 1\n",
    "\n",
    "    for token_id, count in token_counts.items():\n",
    "        token = tokenizer.convert_ids_to_tokens([token_id])[0] \n",
    "        if token in token_to_index:\n",
    "            idx = token_to_index[token]\n",
    "            tf_vector[idx] = count\n",
    "    \n",
    "    query_embeddings[quer_id] = tf_vector\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosins = []\n",
    "for quer_id, query_vector in query_embeddings.items():\n",
    "    similarity = defaultdict(float)\n",
    "    for doc_id, doc_vector in tf_matrix.items():\n",
    "        cos_sim = np.dot(query_vector, doc_vector)/(norm(query_vector) * norm(doc_vector))\n",
    "        similarity[doc_id] = cos_sim\n",
    "    cosins.append(similarity)\n",
    "        \n",
    "for i in range(len(queries)):\n",
    "    cosins[i] = dict(sorted(cosins[i].items(), key=lambda item:item[1], reverse=True))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MP@K criteria for TF embedding: 12.088888888888874%\n"
     ]
    }
   ],
   "source": [
    "mp_at_k = 0\n",
    "for i in range(1, len(queries)+1):\n",
    "    x = iter(cosins[i-1].items())\n",
    "    p_at_k = 0\n",
    "    for j in range(5):\n",
    "        if f\"{next(x)[0]}\" in relevance_judgments[i]:\n",
    "            p_at_k += 1\n",
    "\n",
    "    p_at_k /= 5\n",
    "    mp_at_k += p_at_k\n",
    "\n",
    "mp_at_k /= len(queries)\n",
    "mp_at_k *= 100\n",
    "print(f\"MP@K criteria for TF embedding: {mp_at_k}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *بخش دوم*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After TF embeddings, we create TF-IDF embedding vectors. \n",
    "The main difference is in their objectives; Taking advantage of mere frequencies (the objective of TF) is not very accurate, since the frequent tokens like '.' attract more attention, but in reality they are not very remarkable. \n",
    "\n",
    "TF-IDF method uses the Inverse Document Frequency which reduces their importance by their appearance in the all documents.\n",
    "(For conveniance and lower computations, I have put all document tokens in all_tokens. Also, I have avoided to build a sparse matrix and just put the non-zero tokens with their values in dictionary; This reduces the processes significantly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate TF for each term in each document\n",
    "tfs = {}\n",
    "for doc_id, tokens in all_tokens.items():\n",
    "    term_counts = Counter(tokens)\n",
    "    doc_len = doc_lengths[doc_id]\n",
    "    tfs[doc_id] = {term: count / doc_len for term, count in term_counts.items()}\n",
    "    tfs[doc_id] = dict(sorted(tfs[doc_id].items(), key=lambda item:item[1], reverse=True))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate DF for each term\n",
    "dfs = defaultdict(int)\n",
    "for tokens in all_tokens.values():\n",
    "    unique_tokens = set(tokens)\n",
    "    for term in unique_tokens:\n",
    "        dfs[term] += 1\n",
    "\n",
    "# Calculate IDF for each term\n",
    "docs_num = len(documents)\n",
    "idfs = {term: math.log(docs_num/df)+1 for term, df in dfs.items()}\n",
    "\n",
    "tf_idfs = defaultdict(int)\n",
    "for doc_id, tf_values in tfs.items():\n",
    "    tf_idfs[doc_id] = {term: tf * idfs[term] for term, tf in tf_values.items()}\n",
    "    tf_idfs[doc_id] = dict(sorted(tf_idfs[doc_id].items(), key=lambda item: item[1], reverse=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-4-b:\n",
    "In this section we evalute MP@5 criteria for TF-IDF Embedding vectors. This method is more accurate than other two with the MP@5 of 25%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_tfs = defaultdict(int)\n",
    "\n",
    "for quer_id, text in queries.items():\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    term_counts = Counter(tokens)\n",
    "    query_len = len(tokens)\n",
    "    query_tfs[quer_id] = {term: count / query_len for term, count in term_counts.items()}\n",
    "    query_tfs[quer_id] = dict(sorted(query_tfs[quer_id].items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "query_tf_idfs = defaultdict(int)\n",
    "for quer_id, tf_values in query_tfs.items():\n",
    "    query_tf_idfs[quer_id] = {term: tf * idfs[term] for term, tf in tf_values.items() if term in idfs}\n",
    "    query_tf_idfs[quer_id] = dict(sorted(query_tf_idfs[quer_id].items(), key=lambda item: item[1], reverse=True))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosins = []\n",
    "for quer_id, query_tf_idf in query_tf_idfs.items():\n",
    "    similarity = defaultdict(float)\n",
    "    for doc_id, doc_tf_idf in tf_idfs.items():\n",
    "        dot_product = 0\n",
    "        for token in query_tf_idf:\n",
    "            if token in doc_tf_idf:\n",
    "                dot_product += query_tf_idf[token] * doc_tf_idf[token]\n",
    "            \n",
    "        cos_sim = dot_product / (norm(list(query_tf_idf.values())) * norm(list(doc_tf_idf.values())))\n",
    "        similarity[doc_id] = cos_sim\n",
    "\n",
    "    cosins.append(similarity)\n",
    "        \n",
    "for i in range(len(queries)):\n",
    "    cosins[i] = dict(sorted(cosins[i].items(), key=lambda item:item[1], reverse=True))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MP@5 criteria for TF-IDF embedding: 25.422222222222242%\n"
     ]
    }
   ],
   "source": [
    "mp_at_k = 0\n",
    "for i in range(1, len(queries)+1):\n",
    "    x = iter(cosins[i-1].items())\n",
    "    p_at_k = 0\n",
    "    for j in range(5):\n",
    "        if f\"{next(x)[0]}\" in relevance_judgments[i]:\n",
    "            p_at_k += 1\n",
    "\n",
    "    p_at_k /= 5\n",
    "    mp_at_k += p_at_k\n",
    "\n",
    "mp_at_k /= len(queries)\n",
    "mp_at_k\n",
    "mp_at_k *= 100\n",
    "print(f\"MP@5 criteria for TF-IDF embedding: {mp_at_k}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *بخش سوم*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### الف"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we create the PPMI Embedding vectors. PPMI method emphasizes meaningful relationships between words by assigning higher scores to pairs that appear together more often than expected by chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.vocab)\n",
    "context_window = 5\n",
    "\n",
    "term_freq = defaultdict(int)\n",
    "co_occurrence = defaultdict(lambda: defaultdict(int))\n",
    "total_tokens_num = 0\n",
    "\n",
    "for doc_id, text in documents.items():\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    tokens_num = len(token_ids)\n",
    "    total_tokens_num += tokens_num\n",
    "\n",
    "    for i, token_id in enumerate(token_ids):\n",
    "        term_freq[token_id] += 1\n",
    "        start_point = max(i - context_window, 0)\n",
    "        end_point = min(i + context_window + 1, tokens_num)\n",
    "\n",
    "        for j in range(start_point, end_point):\n",
    "            if j != i:\n",
    "                co_occurrence[token_id][token_ids[j]] += 1\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppmis = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "for term_x in co_occurrence:\n",
    "    for term_y in co_occurrence[term_x]:\n",
    "        p_xy = co_occurrence[term_x][term_y] / total_tokens_num\n",
    "        p_x = term_freq[term_x] / total_tokens_num\n",
    "        p_y = term_freq[term_y] / total_tokens_num\n",
    "\n",
    "        # Calculate PMI\n",
    "        pmi = np.log2(p_xy / (p_x * p_y)) if p_xy > 0 else 0\n",
    "\n",
    "        # Calculate PPMI\n",
    "        ppmis[term_x][term_y] = max(pmi, 0)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ب"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creation of embedding vectors for each token, now we should calculate the Document and Query embeddings by taking an average from all of the embedding vectors of that document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Document Embeddings using PPMI values\n",
    "doc_embeddings = {}\n",
    "\n",
    "for doc_id, text in documents.items():\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)  \n",
    "\n",
    "    doc_vector = np.zeros(vocab_size)\n",
    "\n",
    "    for token_id in token_ids:\n",
    "        ppmi_values = np.array([ppmis[token_id].get(other_id, 0) for other_id in ppmis[token_id]])\n",
    "        doc_vector[token_id] = np.mean(ppmi_values)\n",
    "\n",
    "    doc_embeddings[doc_id] = doc_vector\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "query_embeddings = {}\n",
    "\n",
    "for query_id, text in queries.items():\n",
    "    query_tokens = tokenizer.tokenize(text)\n",
    "    query_token_ids = tokenizer.convert_tokens_to_ids(query_tokens)  # Convert to token IDs\n",
    "\n",
    "    # Initialize a zero vector for the query with the size of the vocabulary\n",
    "    query_vector = np.zeros(vocab_size)\n",
    "\n",
    "    for token_id in query_token_ids:\n",
    "        # Take the average of PPMIs between the current term and all others\n",
    "        ppmi_values = np.array([ppmis[token_id].get(other_id, 0) for other_id in ppmis[token_id]])\n",
    "        query_vector[token_id] = np.mean(ppmi_values)\n",
    "\n",
    "    query_embeddings[query_id] = query_vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-4-c:\n",
    "In this section we calculate the MP@5 criteria for PPMI method. This method has around 16% correct relevance judgments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosins = []\n",
    "for quer_id, query_vector in query_embeddings.items():\n",
    "    similarity = defaultdict(float)\n",
    "    for doc_id, doc_vector in doc_embeddings.items():\n",
    "        cos_sim = np.dot(query_vector, doc_vector)/(norm(query_vector) * norm(doc_vector))\n",
    "        similarity[doc_id] = cos_sim\n",
    "    cosins.append(similarity)\n",
    "        \n",
    "for i in range(len(queries)):\n",
    "    cosins[i] = dict(sorted(cosins[i].items(), key=lambda item:item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MP@5 criteria for PPMI embedding: 25.422222222222242%\n"
     ]
    }
   ],
   "source": [
    "mp_at_k = 0\n",
    "for i in range(1, len(queries)+1):\n",
    "    x = iter(cosins[i-1].items())\n",
    "    p_at_k = 0\n",
    "    for j in range(5):\n",
    "        if f\"{next(x)[0]}\" in relevance_judgments[i]:\n",
    "            p_at_k += 1\n",
    "\n",
    "    p_at_k /= 5\n",
    "    mp_at_k += p_at_k\n",
    "\n",
    "mp_at_k /= len(queries)\n",
    "mp_at_k *= 100\n",
    "print(f\"MP@5 criteria for PPMI embedding: {mp_at_k}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *بخش چهارم*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### الف"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-4-a has been provided after بخش اول"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ب"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-4-b has been provided after بخش دوم"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ج"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-4-c has been provided after بخش سوم"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
